{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n",
    "\n",
    "As a first operation we are going to clean the dataset from all the <MENTION_X> strings to improve the training and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_train_file = \"Datasets/raw_training_data.tsv\"\n",
    "input_test_file = \"Datasets/raw_test_data.tsv\"\n",
    "\n",
    "output_folder = \"OutputDatasets\"\n",
    "output_train_file = \"raw_training_data.tsv\"\n",
    "output_test_file = \"raw_test_data.tsv\"\n",
    "\n",
    "pattern = r\"<(MENTION_\\d+|URL)>\\s*\"\n",
    "\n",
    "def remove_mention(input_file, output_file, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    output_file = os.path.join(output_folder, output_file)\n",
    "    with open(input_file, \"r\", newline=\"\", encoding=\"utf-8\") as file_in, open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as file_out:\n",
    "        reader = csv.reader(file_in, delimiter=\"\\t\")\n",
    "        writer = csv.writer(file_out, delimiter=\"\\t\")\n",
    "\n",
    "        for row in reader:\n",
    "            modified_row = [re.sub(pattern, \"\", cell) for cell in row]\n",
    "            writer.writerow(modified_row)\n",
    "\n",
    "remove_mention(input_train_file, output_train_file, output_folder)\n",
    "remove_mention(input_test_file, output_test_file, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have notice the presence of emojis in the dataset.\n",
    "The emojis must be removed because they are useless and disturbing elements during the execution of the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train_file = \"OutputDatasets/raw_training_data.tsv\"\n",
    "input_test_file = \"OutputDatasets/raw_test_data.tsv\"\n",
    "\n",
    "output_folder = \"OutputDatasetsNoEmoji\"\n",
    "output_train_file = \"raw_training_data.tsv\"\n",
    "output_test_file = \"raw_test_data.tsv\"\n",
    "\n",
    "def get_emoji_regexp():\n",
    "    emojis = sorted(emoji.EMOJI_DATA, key=len, reverse=True)\n",
    "    pattern = u'(' + u'|'.join(re.escape(u) for u in emojis) + u')'\n",
    "    return re.compile(pattern)\n",
    "\n",
    "def remove_emoji(string):\n",
    "    cleaned = re.sub(get_emoji_regexp(), \"\", string)\n",
    "    return cleaned.strip()\n",
    "\n",
    "def remove_emoji_from_tsv(input_file, output_file, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    output_file = os.path.join(output_folder, output_file)\n",
    "    with open(input_file, \"r\", newline=\"\", encoding=\"utf-8\") as file_in, open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as file_out:\n",
    "        reader = csv.reader(file_in, delimiter=\"\\t\")\n",
    "        writer = csv.writer(file_out, delimiter=\"\\t\")\n",
    "        for row in reader:\n",
    "            modified_row = [remove_emoji(cell) for cell in row]\n",
    "            writer.writerow(modified_row)\n",
    "\n",
    "remove_emoji_from_tsv(input_train_file, output_train_file, output_folder)\n",
    "remove_emoji_from_tsv(input_test_file, output_test_file, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the train set and the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Fatti trovare  te lo do volentieri e ti sborro in bocca\n",
      "Misogynous: 1\n",
      "Aggressiveness: 1\n",
      "\n",
      "Text: Tu dovresti ricominciare dai semafori a fare la lavavetri..ma tranquilla tanto il vitalizio ti resterà in gola\n",
      "Misogynous: 1\n",
      "Aggressiveness: 1\n",
      "\n",
      "Text: Amore,sei presentabile? Xchè così via Skype ti faccio conoscere i miei parenti...\" e fu così che da un tablet ho conosciuto i parenti terroni della mia tettona,prendendomi un \"avete già finito di pranzare? beh si,voi al nord siete diversi...\" Dal nord è tutto,a voi...\"\n",
      "Misogynous: 1\n",
      "Aggressiveness: 1\n",
      "\n",
      "Text: Salvo poi mandare la culona a Mosca, aummaumm, per farsi dare da Putin commesse multimiliardarie e metterlo in quel posto ai FRATELLI della UE (tra i quali NOI)\n",
      "Misogynous: 1\n",
      "Aggressiveness: 0\n",
      "\n",
      "Text: Vediamo Gentiloni, è ora di finirla di essere servili! Pensiamo al danno che la Francia ci ha fatto con Sarkosy e la culona della Merkel con il bombardamento della Libia\n",
      "Misogynous: 1\n",
      "Aggressiveness: 1\n",
      "\n",
      "Text: Aveva voglia di gridare tutta la mia rabbia ma quel maledetto nodo in gola bloccava tutto. Ogni urlo si trasformava in lacrime. Quanto odiava piangere, non lo faceva mai. Guardando le luci della notte si addormentò sfinita con una musica dolce che le faceva da ninna nannaLaila\n",
      "Misogynous: 0\n",
      "Aggressiveness: 0\n",
      "\n",
      "Text: Lei è acida perché non ha figli penso che darebbe fastidio a qualsiasi donna. Che schifo ... #TemptationIsland\n",
      "Misogynous: 0\n",
      "Aggressiveness: 0\n",
      "\n",
      "Text: Ma quanto è brutto sentirsi dire dal proprio fidanzato che sei acida solo perché non hai avuto figli.MA TU CHE CAZZO NE SAI SE ANTONELLA PER QUESTA COSA GIÀ NE SOFFRE DI SUO MA COMECTI PERMETTI A DISTRUGGERE L’EMOTIVITÀ DI UNA PERSONA MERDA RARA. #TemptationIsland\n",
      "Misogynous: 0\n",
      "Aggressiveness: 0\n",
      "\n",
      "Text: Per chi ci facciamo venire il groppo in gola stasera? #techetechete\n",
      "Misogynous: 0\n",
      "Aggressiveness: 0\n",
      "\n",
      "Text: Ti sborro io\n",
      "Misogynous: 1\n",
      "Aggressiveness: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_train_file = \"OutputDatasetsNoEmoji/raw_training_data.tsv\"\n",
    "input_test_file = \"OutputDatasetsNoEmoji/raw_test_data.tsv\"\n",
    "\n",
    "def read_set(input_set):\n",
    "    features = []\n",
    "    labels = []\n",
    "    with open(input_set, 'r', encoding='utf-8') as tsv_file:\n",
    "        tsv_reader = csv.reader(tsv_file, delimiter='\\t')\n",
    "        next(tsv_reader)  # Salta l'intestazione del file\n",
    "\n",
    "        # Legge le righe del file e salva le features e le labels\n",
    "        for row in tsv_reader:\n",
    "            text = row[1]\n",
    "            misogynous = int(row[2])\n",
    "            aggressiveness = int(row[3])\n",
    "\n",
    "            features.append(text)\n",
    "            labels.append((misogynous, aggressiveness))\n",
    "    return features, labels\n",
    "\n",
    "# Praticamente train_set[0] per le features e train_set[1] per le labels\n",
    "train_set = read_set(input_train_file)\n",
    "test_set = read_set(input_test_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
